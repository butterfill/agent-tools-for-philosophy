
%!TEX root = master.tex

\chapter{Core Knowledge}
\label{cha:core-knowledge}

In attempting to understanding how humans first come to know simple facts about particular physical objects,
one important discovery is that four-month-olds can segment objects, represent them as persisting and track their causal interactions.
Further, their abilities to do these things can be described, at least approximately, by a set of principles about the behaviour of physical objects, namely the Principles of Object Perception (see \cref{cha:principles-object-perception,cha:simple-view}).
Given this, it is natural to wonder whether the Principles might not merely describe but also explain infants’ (and adults’) abilities
(see \cref{table:levels-claims-about-the-principles} on page \pageref{table:levels-claims-about-the-principles}).

If the Principles of Object Perception somehow explain infants’ abilities, there must be some link between the Principles and individual minds.
A natural first idea is that this link involves belief or knowledge: the Principles are things that infants believe or know.
Add the further claim that infants acquire beliefs or knowledge about particular physical objects and their interactions by making inferences from these principles together with perceptual information about the arrangement of surfaces in space and we arrive at the Simple View (see \cref{sec:simple-view}).

The Simple View is attractive insofar as it does not require postulating novel kinds of mental states or processes. But it systematically generates incorrect predictions (see \cref{cha:linking-problem}), so must be rejected.
It appears we cannot understand how the principles might be linked to individual minds by any of the most familiar kinds of mental states---the perceptual, motoric and epistemic. 
The question of what links the Principles to individual minds is therefore a problem.
This is the Linking Problem, introduced in \cref{cha:linking-problem}.
In this chapter we will investigate a leading attempt to solve it by postulating something called ‘core knowledge’.



\section{What Is Core Knowledge?}
\label{sec:core-knowledge}
In attempting to solve the \gls{Linking Problem} we have so far considered only the most familiar kinds of mental representations---knowledge states, beliefs, perceptions and the like (see \cref{sec:the-challenge}).
Does understanding the developmental emergence of knowledge require postulating a novel kind of mental representation?

Carey suggests it does.
According to her,
%
\begin{quote}
  ‘there is a third%
\footnote{%
Since core knowledge is clearly supposed to be distinct from epistemic, perceptual and motor representations, we should really say that core knowledge is supposed to be a \emph{fourth type} of state.
} 
type of conceptual structure, dubbed “\gls{core knowledge}” \ldots\ that differs systematically from both sensory/perceptual representation \ldots\ and \ldots\ knowledge’
  \citep[p.~10]{carey:2009_origin}
\end{quote}
%
Could core knowledge be what \glslink{Linking Problem}{links} the \glslink{Principles of Object Perception}{principles} describing infants’ earliest abilities concerning physical objects to their minds? %done

To answer this question we first need to know what \gls{core knowledge} is.
Core knowledge is defined in terms of core systems.
For someone to have \emph{\gls{core knowledge}} of a particular principle or fact is for her to have a core system where
either the core system includes a representation of that principle or else the principle plays a special role in describing the core system.%
\footnote{%
An infelicitous consequence of this definition is that you can have core knowledge of things that are untrue.
Perhaps for this reason, \citet[p.~10]{carey:2009_origin} recommends the term ‘core cognition’ for states of core knowledge.
I stick to the term ‘core knowledge’ because it is so widely used.
}
But what is a core system?

Start with an analogy:
%
\begin{quote}
‘Just as humans are endowed with multiple, specialized perceptual systems, so we are endowed with multiple systems for representing and reasoning about entities of different kinds’ \citep[p~517]{Carey:1996hl}.
\end{quote}
%
As examples of ‘specialized perceptual systems', Carey and Spelke mention things like perceiving colour, depth or melodies.
The operations of such systems are to a significant extent independent of each other, and of capacities to know things about colour, depth or melodies.
So the idea is that core systems are independent in whatever ways some perceptual systems are.


The analogy with perceptual systems is helpful for getting a rough, intuitive fix on what a core system is supposed to be.
But what is a core system?

\Glspl{core system} are standardly identified by listing their characteristic features.
 \citet[p~520]{Carey:1996hl} write that ‘core systems are:
 %
 \begin{enumerate}
\item largely innate
\item encapsulated
\item unchanging
\item arising from phylogenetically old systems
\item built upon the output of innate perceptual analyzers’
\end{enumerate}
%
The exact list of properties has varied over time, but not in ways that matter for our purposes.
What matters for now is just that core knowledge is defined in terms of core systems,
and \glspl{core system} are defined by a list of features which probably includes most of those just mentioned.

In addition, core knowledge is sometimes held to be
specific to quite narrow categories of event and not to grow by means of generalization (\citealp[p.~57]{Baillargeon:2002hb}; \citealp[p.~344]{Baillargeon:2001ll}).
It may also be best understood as a collection of rules rather than a coherent theory \citep[p.~82]{Baillargeon:2002hb}.
These claims do not follow directly from definitions: they are based on observations of limits on the abilities which, according to the theory, are underpinned by core knowledge.

Are the notions of core knowledge and core system useful tools for solving the Linking Problem?
And will they enable us to describe—and maybe explain—what is in between mindless behaviour and more familiar kinds of mental states like knowledge, belief and perception?

Consider what I will call the \emph{\gls{Core Knowledge View}}:
\begin{quote}
  The \gls{Principles of Object Perception} are not things infants know but rather encoded in their \gls{core knowledge}.
  The operations of core system enables
  this core knowledge, together with perceptual inputs, to generate expectations concerning particular physical objects.
  These expectations are not knowledge states but  representations in core systems.
\end{quote}
The Core Knowledge View is an alternative to the \gls{Simple View}.
According to the \gls{Simple View}, infants know  the \gls{Principles of Object Perception}.
But on the Core Knowledge View, infants may lack beliefs about, or knowledge of, simple facts about particular physical objects while having representations of such facts as a consequence of a the operation of a core system.
This is an advantage of the Core Knowledge View.
It means that the Core Knowledge View will not generate the incorrect predictions which follow from the Simple View.

Not all researchers sympathetic to the existence of core systems would accept the Core Knowledge View.
They may instead hold that the operations of core systems result directly in beliefs, or knowledge states, concerning particular physical objects
(compare \citealp[pp.~193–4]{Leslie:1988ct} on the outputs of modules).
%“The module … automatically provides a conceptual identification of its input for central thought … in exactly the right format for inferential processes” (Leslie 1988: 193–4 my italics).
But holding this means that invoking core knowledge will not enable you to respond to the objections to the \gls{Simple View} we have encountered (in \crefrange{sec:against-simple-view}{sec:furth-evid-against}).
From our point of view, this would defeat the point of invoking core knowledge,
which is to solve the \gls{Linking Problem}.


\section{Can Core Knowledge Solve the Linking Problem?}
\label{sec:against-core-systems}
Is the \gls{Core Knowledge View} a solution to the \gls{Linking Problem}?
As we have just seen, the Core Knowledge View does not generate the incorrect predictions generated by the \gls{Simple View}.
Instead it has a complementary defect.

In evaluating the Simple View earlier in this chapter, we identified a puzzling pattern of evidence.
The pattern is summarised in \vref{table:occlusion-vs-endarkening}.
A solution to the Linking Problem should enable us to explain this puzzling pattern.
But consider the list features used to define core systems (in \cref{sec:core-knowledge}): they are largely innate, encapsulated and so on.
Which of these features explain the discrepancy between
measures on which infants do, and measures on which they do not, manifest their abilities to track physical objects?
Why do they fail on some manual search tasks and but pass some violation-of-expectation tasks
when the mode of disappearance is occlusion?
And, equally pressingly, why do they do the converse (pass search but fail violation-of-expectation tasks) when the mode of disappearance is endarkening
(see \cref{table:occlusion-vs-endarkening} on page \pageref{table:occlusion-vs-endarkening})?

None of the features specified in defining \glspl{core system} and \gls{core knowledge} are relevant.
The \gls{Core Knowledge View} is consistent with the puzzling pattern of findings about infants’ abilities concerning physical objects.
But it would be equally consistent with a converse pattern.
If it had turned out, contrary to fact that six-month-olds succeeded in manual searches while failing to show that they can represent briefly unperceived objects in violation-of-expectation tasks when the mode of disappearance is occlusion,
the Core Knowledge View would be no less appealing.

\citet[pp.~441--2]{Spelke:1994oz} writes that core knowledge has limited effects on behaviour, being usually manifest in the control of attention (as measured by \gls{dishabituation}, gaze, and looking times) and rarely or never manifest in purposive actions.
Of course, this is exactly what needs to be true if invoking core knowledge is to solve the Linking Problem.
Or almost exactly---core knowledge would need to be manifest in purposive actions and not gaze when objects disappear by endarkening (see \cref{sec:even-worse-for-the-simple-view}).
And maybe this is true. 
But none of the the ways core knowledge is standardly introduced provide any reason to suppose that this is true.
And this means that we cannot know whether it is really core knowledge that solves the Linking Problem.


\citet{carey:2009_origin} suggests a further feature of core knowledge: it is an \gls{iconic representation}, unlike ordinary knowledge.
That is, core knowledge has something in common with paper photographs and maps: cutting a photograph down the middle usually gives you two photographs, each of which is a photograph of a smaller part of what the whole photograph was of.
In saying that core knowledge is iconic, Carey means that it is structurally similar: a piece of core knowledge has proper parts which are themselves bits of core knowledge about something smaller.
This is an interesting idea, but is it relevant to solving the Linking Problem?
The problem, once again, is that iconicity doesn't bear on the puzzling pattern of findings.
An adequate solution to the Linking Problem should distinguish between the actual world in which six-month-olds cannot manually search for objects and an alternative, merely possible world in which those infants cannot represent briefly unperceived objects in violation-of-expectation tasks when the mode of disappearance is occlusion.
Invoking iconicity would be no less compelling in the alternative, merely possible world.
So even knowing whether infants’ earliest representations of objects are iconic would not be enough to solve the Linking Problem.

The \gls{Core Knowledge View} offers an improvement over the idea that four-month-olds know facts about briefly unperceived objects insofar it does not generate incorrect predictions.
But this seems to be mainly because the Core Knowledge View fails to generate any relevant predictions at all.

You might object that two questions are being conflated.
One question is the \gls{Linking Problem}: What links the \gls{Principles of Object Perception} to infants’ minds?
On the \gls{Core Knowledge View}, the answer is that the principles are encoded in core knowledge.
Another question is, What explains the puzzling patterns in infants’ earliest abilities concerning physical objects?
You might object that this is a separate question, and not one that a proponent of the Core Knowledge View needs to answer.

%And you would be in good company: the assumption that they are separate issues is at least implicit in much research in this area.
It is true that we should distinguish these questions, but they are closely related.
How can we tell whether a proposed solution to the Linking Problem is correct?
The Linking Problem arises because we want a theory of infants’ abilities which is not merely \gls{descriptively adequate} but also \gls{explanatorily adequate} (see \cref{sec:simple-view}).
The point of solving the Linking Problem is to explain and predict facts about infants’ abilities.
Success in doing this is what allows us to determine the likely correctness of a proposed solution.
As the Core Knowledge View neither explains puzzling patterns in infants’ abilities nor generates fine-grained novel predictions, there is no way of knowing whether it solves the Linking Problem.

% things that, on the standard approach, you cannot explain or predict with core knowledge.


\section{How Not to Define Something}
\label{sec:core-knowledge-is-badly-defined}

The failure of the Core Knowledge View to enable us to solve the Linking Problem is related to the way \gls{core knowledge} and \gls{core system} are defined.
The standard approach to saying what core knowledge and core systems are is essentially just to give a list of features (as we saw in  \cref{sec:core-knowledge}).
Can this approach yield a notion of core knowledge that will be useful in explaining cognitive development?

When confronted with a list of features, it is natural to ask why those particular features should ‘come as a package’
(as  \citet[p.~759]{adolphs_conceptual_2010} and \citet[p.~537]{keren_two_2009} both stress in a different context).
%they are talking about a different case, however.
Why, for instance, should we accept that core systems are both largely innate and largely unchanging through development?
What unifies these features?
\citet{Baillargeon:2002hb} agrees that infants’ abilities to represent objects may be largely innate, but she also argues that they undergo substantial change as a result of learning over the first year of life.
There is nothing obviously incoherent about this combination of claims.
It is also conceivable that future discoveries could support the opposite combination of views:
infants’ abilities to represent objects are not innate but a consequence of learning in the first months of life; and, once in place, these are largely unchanging throughout development.
%(On the absence of evidence for the innateness of infants’ abilities to represent objects, see *ref=innateness.)
As far as we know, there is no compelling reason to accept that the features used to define core systems should all come as a package.


The approach to defining core systems that we have followed means that to claim that infants have core systems is to make a bold conjecture.
In general, bolder conjectures are better.
But in this case, boldness is merely recklessness.
The conjecture is bold merely because multiple claims have been artificially packaged together.
It is not a theory about the architecture of the mind: it is a parlay bet.

I don’t mean to imply that there is anything intrinsically wrong with parlay bets.
(A parlay bet is one which combines bets on several outcomes and pays out only if all the component bets are right.)
After all, such bets can pay off nicely if the things go your way.
But a parlay bet is not a theory.
In invoking core systems and core knowledge, we are aiming to understand something about ‘the architecture of the mind’ \citep[p.~67]{carey:2009_origin}.
So core knowledge is supposed to be an explanatory notion.
But no explanatory notion can be adequately characterised merely by listing features.
% Explanatory power would depend on at least identifying what unifies these features.
We will not get far in understanding the mind’s architecture merely by listing features.

In order to be in a position to invoke \gls{core knowledge} in solving the \gls{Linking Problem} and
explaining how humans first come to know facts about particular physical objects (and facts in other domains too), we will need a different approach to understanding what core knowledge is.



\section{Will Invoking Modularity Help?}
\label{sec:modularity}
Our aim is to solve the \gls{Linking Problem}, that is, to understand what links the principles describing infants’ earliest abilities concerning physical objects to their minds.
The notion of \gls{core knowledge} appears to provide a way forward (see \cref{sec:core-knowledge}).
But the standard approach to defining core knowledge (and core systems) makes it unsuitable for constructing explanations (see \cref{sec:against-core-systems}).
This looks like the sort of problem a philosopher should be able to help with.

While philosophers have rarely thought about core knowledge in depth,
there has been much discussion of a related notion, namely modularity.
\citet[p.~101]{Fodor:1983dg} characterises modules as systems which are among other things
innate and encapsulated.
Both of these properties have been invoked in characterising core systems too (see \vref{sec:core-knowledge}).
There are further points of similarity between modules and core systems.
Fodor says modules are domain specific.
That is, one module might concern physical objects while another would concern agency and action, say.
This is exactly how core systems are thought of.

In some ways, Fodor’s notion of module is broader than that of core system.
According to Fodor, modules are ‘systems whose operations present the world to thought’ \citep[][p.~40]{Fodor:1983dg}.
They therefore include perceptual systems, which are not usually regarded as core systems.
But as Spelke and Carey introduce core systems by comparison with perceptual systems (\citealp[p.~517]{Carey:1996hl}; \citealp[p.~278]{Spelke:2003fc}),
this difference is plausibly terminological.
% \citet[p.~278]{Spelke:2003fc}): ‘Just as infant animals have specialized perceptual systems for detecting particular kinds of sensory information and specialized motor systems guiding particular kinds of actions, infant animals have specialized, task-specific cognitive systems: systems for representing material objects, navigating through the spatial layout, recognizing and interacting with other animals, and the like.’

Despite the overlap in features used to characterise core systems and modules, there are also some differences.
Fodor stipulates that modules are computational systems, and that they exhibit neural specificity (so can be identified neurophysiologically).
For their part, Spelke and Carey specify that core systems arise from systems already present in the evolutionary ancestors of modern humans (see \cref{sec:core-knowledge}).

The pattern of similarities and differences makes it hard to know how modules relate to core systems.
Some appear to hold, roughly, that core systems are modules \citep[p.~137]{spelke:1995_spatiotemporal}, or that the account of core systems is a revision of Fodor’s account of modularity \citep{Hermer:1996ke}.
% \citealp[p.~137]{spelke:1995_spatiotemporal}: ‘In Fodor’s (1983) terms, visual tracking and preferential looking each may depend on modular mechanisms.’
It has also been suggested that core systems compete with modules in the sense that the mind can contain one or the other but not both \citep{Spelke:1988xc}; and, alternatively, that core systems might exist alongside modules \citep{Carey:1995so}.
As things stand, my sense is that there is not so much evidence concerning the features associated with core systems and modules that we can make empirically motivated distinctions between multiple different theories in this area.
(To illustrate, see \cref{sec:poverty-of-poverty-of-stimulus} on evidence for innateness.)
I therefore provisionally take ‘module’ and ‘core system’ to be different labels for a single thing.

Overall, existing theoretical discussions of modularity do not seem help with the \gls{Linking Problem}.
Modules are standardly defined the same way that core systems are standardly defined: by stipulating a collection of features, none of which allow us to explain the puzzling patterns in infants’ abilities concerning physical objects (see \vref{table:occlusion-vs-endarkening}).
For our purpose, these accounts of modularity share the defects of the standard account of core systems.
To recap (see \cref{sec:against-core-systems}),
none of the features associated with core knowledge or modularity explain the actual pattern of discrepancies in six-month-olds’ abilities to track briefly unperceived objects.
Exactly the same features could be invoked in a world in which there were a different  pattern of discrepancies. 
This is related to the way the notions of core knowledge and modularity are introduced: by merely listing features, we are making a parlay bet where we should be providing a theory.
If we want to solve the \gls{Linking Problem}, we will need a deeper understanding.


\section{Conclusion}


One leading approach to solving the Linking Problem  hinges on the notion of \gls{core knowledge}
(\cref{sec:core-knowledge}).
According to the \gls{Core Knowledge View}, infants’ earliest representations of physical objects are representations in core systems.


This view is initially promising insofar as it does not generate the same incorrect predictions that the \gls{Simple View} does.
But it also fails to explain what we need to explain, and to generate the predictions we need to generate, if we are to know we have solved the \gls{Linking Problem}.
As we saw in \cref{cha:linking-problem}, there are surprising patterns in when infants of different ages manifest abilities to represent objects as persisting (see \crefrange{sec:against-simple-view}{sec:furth-evid-against}).
Appealing to a general theory core knowledge or modularity will not enable us to explain why infants manifest abilities to represent objects as persisting when reaching in the dark but not when reaching behind a barrier.
Existing theories of core knowledge are equally compatible with the converse pattern.
Nor do these theories generate fine-grained, readily testable new predictions about the conditions under which infants will manifest their abilities to represent objects as persisting.

%
% This failure is probably due to defining core systems by listing some features.
% This means  we end up without an explanatorily robust, nonarbitrary notion of core knowledge (see \cref{sec:against-core-systems}).


What next?
There are many other general theories about states and processes that are neither mindless nor like knowledge, belief and other commonsense psychological states (including, for example, \citet{Stich:1978wb} on subdoxastic states and \citet{Cohen:1992nx} on belief versus acceptance).
My guess, though, is that these general theories will prove likewise unable to provide the kind of explanations and to generate the sort of predictions we need.
Instead of elaborating on a general theory that is supposed to work for any domain of knowledge, we should consider in more detail what is known about object cognition in adults.


% But sometimes when you are looking for a theory, less is more.
% Resist the temptation to respond to the \gls{Linking Problem} by invoking a very general theory.
% Instead consider a brilliant conjecture about what underlies infants’ abilities concerning physical objects.





%%% Local Variables:
%%% TeX-master: "master"
%%% End:
