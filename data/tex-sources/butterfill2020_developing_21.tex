%!TEX root = master.tex


\chapter{Syntax}
\label{cha:syntax}

On the view elaborated in this book,
the developmental emergence of knowledge involves two primary ingredients, core knowledge and joint action.
The need for these two things to work together is clearest in the case of knowledge of language.

So far we have considered communication with words, which appears from an infants’ point of view as simply joint action (or so I argued in \cref{cha:words}).
But there is more to communication than words.
There is also syntax, the patterns in the ways we use words.
You can see that syntax matters by thinking about two sentences, ‘Ayesha bit the lion’ and ‘The lion bit Ayesha’.
Although they contain the same words, you can use these sentences to convey quite different messages.
Why is that?
It must be due to the order in which the words appear.
And the order is significant only because you and I consistently treat the sentences as having a certain syntactic structure.
Syntax seems so simple, but it is
syntactic abilities that enable us to make the transition from merely referential communication to \gls{propositional communication}.
And this matters because propositional communication enables us to express and share facts.


% So far we have considered examples of core knowledge.
% But we have ignored a paradigm case,
% one which has inspired much work on this topic (although it is not a case Spelke or Carey would recognize! *todo: stress throughout) \ldots\



\section{Syntax in Adults}
\label{sec:syntax-adults}
Start by considering what we know about adults' syntactic abilities.
Contrast these two sequences (to adapt a famous example from Chomsky):
%
\begin{enumerate}
  \item The turnip of shapely knowing isn't yet buttressed by death.
\item  *The buttressed turnip shapely knowing yet isn't of by death.
\end{enumerate}
%
Whereas the second sequence of words is not a sentence, the first is widely recognised as a sentence---although not one you are likely to make much sense of.
As this illustrates,
humans who communicate by language can usually recognise whether or not sequences of words are sentences, and can do so independently of whether they understand them.
That is, they can \gls{track syntactic properties}.

What underpins adults’ abilities to track syntactic properties?
This ability cannot be based merely on past exposure to particular sentences because adults can often distinguish entirely novel sentences from nonsentences.
To describe the ability, it seems that we will need principles of syntax.
The principles must allow us to determine, for an arbitrary sequence of words, whether or not it is a sentence.

How do principles of syntax relate to the abilities of actual language users?
To simplify answering this question it is useful to recycle the three-fold distinction between \glslink{formally adequate}{formally}, \glslink{descriptively adequate}{descriptively} and \gls{explanatorily adequate} (see \vref{table:levels-claims-about-the-principles}).
Consider formal adequacy.
Imagine someone who is omniscient except concerning which sequences of words are sentences, and who has unlimited cognitive resources.
Suppose this person took certain principles of syntax to be true concerning a particular language.
Could she now say, for any sequence of words, whether it is a sentence of that language?
If she could, these principles are formally adequate for the language.
Although constructing formally adequate principles of syntax for a language turns out to be a difficult problem \citep[for example,][pp.13--25]{chomsky:1957_syntactic},
it seems clear that the problem can be solved (see \citealp[Chapter 3]{jackendoff:2003_foundations} for an introduction to one approach).
It is also plausible that we could identify principles of syntax which are \gls{descriptively adequate} for a particular group of speakers.
These principles would enable us to predict which sequences of words this group of speakers will identify as sentences.

The controversial issue is \glslink{explanatorily adequate}{explanatory adequacy}.
What is the relation between principles of syntax that are descriptively accurate for a particular language user and the mechanisms which underpin her syntactic abilities?
Inspired by the \gls{Simple View}, we might start with the idea that the language user knows these principles of syntax.
This enables her to apply the principles in just the way a scientist would: she can make inferences from them to determine whether a given sequence of words is a sentence or not.

In the case of syntax, the Simple View clearly generates incorrect predictions.
To illustrate this, it is useful to introduce now an example that we will also need later.
Consider a simple phrase, ‘the red ball.’
In principle, this phrase could have two different syntactic structures, as illustrated in \vref{fig:lidz_2003_fig0}.
The difference in structure may not appear very significant at first.
But consider what would happen if someone said, ‘This red ball is broken, please bring me another one!’
Can you comply by bringing a blue ball, or does the ball have to be red?
The answer turns out to depend on the structure of the phrase ‘this red ball’.
If you think only a red ball will do, you are treating the phrase as having nested structure (compare \vref{fig:lidz_2003_fig0}).%
\footnote{%
This is because the ‘one’  in ‘please bring me another one’ can only refer to something that a constituent of an earlier part of the sentence already introduced, and if the ‘this red ball’ has a flat structure, ‘red ball’ is not a constituent.
}
Many people, including me, would have no idea which structure, flat or nested, they treat phrases like ‘the red ball’ as having.
But consider the Simple View.
According to this view, we know principles of syntax and we apply those principles in inferring the syntactic structures of particular sentences.
So if the Simple View is right, we know that ‘the red ball’ has a nested structure rather than a flat structure.
As a general rule, if you know something and I ask you a question, you can answer on the basis of what you know.
This is almost trivial.
If you know that it is raining and I ask you whether it is raining or dry, you should be able to tell me that it is raining.
Similarly, if I ask you whether  ‘the red ball’ has a nested structure or a flat structure and you know it has a nested structure, you should be able to tell me that.
But few people can do this.

This is not an isolated example.
In the case of syntax, the Simple View manifestly generates systematically incorrect predictions.

% Thoughtful people are even prone acquire fundamentally false beliefs about syntactic features of their own language \citep{pinker:1995_language}.
% If the Simple View were correct, such false beliefs would be unexpected.


\addFigure{lidz_2003_fig0}{%
Two possible structures for ‘the red ball’.
Source: \citet{lidz:2003_what}}

Some linguists clearly struggle with the fact that the Simple View obviously generates incorrect predictions.
Here is Chomsky:
%
\begin{quote}
‘Obviously, every speaker of a language has mastered and internalized a generative grammar that expresses his knowledge of his language.
This is not to say that he is aware of the rules of the grammar or even that he can become aware of them, or that his statements about his intuitive knowledge of the language are necessarily accurate.
\ldots\ it is quite apparent that a speaker's reports and viewpoints about his behavior and his competence may be in error.
Thus a generative grammar attempts to specify what the speaker actually knows, not what he may report about his knowledge’ \citep[p.~8]{chomsky:1965_aspects}.
\end{quote}
%
In this passage Chomsky conflates two issues.
Contrast these questions:
\begin{enumerate}
  \item Is it raining?
  \item Do you know that it is raining?
\end{enumerate}
The first is a question about rain, the second a question about knowledge.
If you know it is raining, then all other things being equal you should be able to answer the first question correctly.
But it is not obvious that you should also be able to answer the second question correctly merely in virtue of knowing that it is raining.
Perhaps we can know things without knowing that we know them.
The Simple View does not obviously predict that language users should be able to answer questions about knowledge on the basis of their knowledge of syntax.
But it does predict that they should be able to correctly answer questions about syntax on that basis.
The fact that they mostly cannot is clearly a reason for rejecting the Simple View.

Linguists sometimes react to this kind of consideration by appearing to suggest that the issue is merely a verbal quibble about the word ‘knowledge’.
For instance, Jackendoff introduces
‘the term f-knowledge (functional knowledge) to describe whatever is in speakers’ heads that enables them to speak and understand their native language(s)’ (\citeyear[p.~652]{jackendoff:2003_precis}; see \citealp[p.~29ff]{jackendoff:2003_foundations}; compare \citet[p.~14]{Chomsky:1995yg} stipulating an ‘I-language’).
This is exactly like switching from ‘knowledge’ to ‘representation’.
It is a way of ignoring questions about explanatory adequacy and the nature of cognitive mechanisms
(see \cref{sec:representation-not-knowledge}).
Jackendoff’s project is to ‘reintegrate the theory of generative grammar into the cognitive sciences,’
and  he shows that insights from the theory create unresolved challenges for cognitive science (for example, \citealp[p.~163ff]{jackendoff:2003_foundations}).
But he nevertheless puts aside a question of explanatory adequacy with a terminological dodge.
This is a sign of  just how difficult achieving explanatory adequacy would be.

The challenge posed by explanatory adequacy remains unresolved.
We must reject the counterpart of the Simple View for principles of syntax because it generates obviously incorrect predictions.
Some linguists, including Chomsky and Jackendoff, offer no substantive alternative.
In fact these two do not even appear to recognise explanatory adequacy as an issue.
Other linguists have argued that pursuit of explanatory adequacy requires rethinking even the most abstract aspects of theories, including the nature and role of syntactic principles (\citet[part III]{croft:2004_cognitive} offer an introduction to one approach).
As things stand, the most we can say is probably just that the Simple View is wrong.
Adults’ abilities to \gls{track syntactic properties} are not a consequence of their knowing principles of syntax.
Although modest, this conclusion turns out to be useful for understanding the developmental emergence of abilities to communicate.

% The failure of the Simple View motivates considering the possibility that there is a \gls{core system} for syntax.
% This  implies that there is a domain-specific, largely inaccessible system for processing linguistic items in accordance with principles of syntax, which appears to be correct.
% It seems reasonable to suppose that if there are any cases of \gls{core knowledge} at all, syntax will turn out to be among them.


\section{Innateness}
% The first question to ask about the emergence of an ability is usually, When does it first appear in development?
%But in the case of syntax, we can start with a more interesting question.
Are syntactic abilities \gls{innate}?
If you are going to discuss whether something is innate, you had better fix on a particular notion of innateness.
There are plenty to choose from, although no one notion seems to be entirely satisfactory \citep[as][argue]{mameli:2011_evaluation}.
I will simply stipulate that for a cognitive ability to be \gls{innate} is for its developmental emergence not to be a direct consequence of data-driven learning.
In short, innate = not learned.

This way of characterising innateness fits perfectly with the most compelling arguments for innateness, which take the form of \glspl{poverty of stimulus argument}.
Such arguments aim to show that some aspect of humans’ syntactic abilities, say, are not entirely  a consequence of data-driven learning (see \citealp{pullum:2002_empirical} for details).
 As we will see in a moment,
 there are some compelling poverty of stimulus arguments.
So any acceptable characterisation of innateness must respect the fact that poverty of stimulus arguments can establish innateness.
And equating innate with not learned, as I propose, is the simplest way to achieve this.

Samuels objects to equating innate  with not learned (see \citealp[p.~139]{Samuels:2004ho}).
He notes that it is unilluminating on the grounds that the notion of  learning is difficult to characterise for much the same reasons that the notion of innateness is.
Samuels aims for a deeper understanding of innateness.
But if the last couple of millennia or so are any guide, philosophical methods do not enable us to give substantial characterisations of nonlogical phenomena.
With this in mind, superficiality in philosophical characterisation can be a virtue---we aim merely for theoretical coherence.
This is why I characterise innateness simply as a matter of not being a direct consequence of data-driven learning.


\section{A Poverty of Stimulus Argument}
\label{sec:pos-argument}
How can we discover whether infants’ syntactic abilities are innate in this sense?
\citet{lidz:2003_what} set out to answer this question using phrases like ‘the red ball’.
As we saw, such phrases can in principle be assigned either of two syntactic structures, one flat and the other nested.
(These were illustrated in \vref{fig:lidz_2003_fig0}.)
\citeauthor{lidz:2003_what} aimed to show that
18-month-old infants already interpret this sort of phrase as having nested structure, and that they could not have learnt to do this just on the basis of their experiences of language.
This would imply that at least some aspects of humans’ syntactic abilities are a consequence of things that are innate.

The first task is to determine how 18-month-old infants interpret phrases like ‘the red ball.’
Suppose someone says, ‘Look, a red ball!  Do you see another one?’
What would you be looking for?
If you were to look for any ball, whether red or not, this would indicate that you had interpreted the phrase as having flat structure.
But if you are like me, you will be looking for another red ball.
This indicates that you interpret the phrase ‘the red ball’ as having nested structure.
We can therefore find out whether some people interpret the phrase as having nested or flat structure by measuring whether they would look for a red ball or just any ball.
This is the perfect approach for 18-month-old infants, since it does not require them to make any verbal responses.
Accordingly, \citeauthor{lidz:2003_what} played infants a recording of sentences like ‘Look, a red ball!  Do you see another one?’
While they heard this recording, they could see a red ball (or other object corresponding to the sentence they heard).
After the recording, the infants were shown two things simultaneously, such a red ball and a blue ball.
It turned out that infants looked significantly longer at the red ball than the blue one.

You might object that this finding is not revealing.
After all, infants’ tendency to look longer at the red ball than at the blue ball might be due to the fact that they have just seen a red ball.
To rule this out, \citeauthor{lidz:2003_what} had a control condition.
This was exactly like the main condition except that the sentence infants heard was like  ‘Look, a red ball!  What do you see now?’.
That is, instead of asking ‘Do you see another one?’, they asked ‘What do you see now?’.
In this control condition, infants showed the opposite pattern in their looking times: they looked significantly longer at the blue ball or other novel object (see \vref{fig:lidz_2003_fig1}).
So infants’ tendency to look longer at the red ball really does indicate that they interpret this phrase as having nested structure.

\addFigure{lidz_2003_fig1}{%
In response to ‘Look, a red ball!  What do you see now?’  (‘Control’), infants look longer at the blue (‘novel’) ball.  But in response to  ‘Look, a red ball!  Do you see another one?’ (‘Anaphoric’), infants look longer at the red (‘familiar’) ball.  Source: \citet[figure~1]{lidz:2004_reaffirming}}

The fact that 18-month-olds tend to interpret phrases like ‘the red ball’ as having nested structure is not by itself evidence for innateness.
We also need evidence that infants could not have learnt the nested structure on the basis of experiences of language.
\citet{lidz:2003_what} aimed to provide this by analysing a large collection of around 45000 utterances directed to children infants.
In all of these utterances, they found only two which could have indicated nested structure to infants.
By contrast, there were four ungrammatical uses of ‘one’.
This survey suggests that 18-month-olds’ experiences of language do not provide them with a basis for learning that phrases like ‘the red ball’ have nested structure.

Putting \citeauthor{lidz:2003_what}’s  two findings together gives us a \gls{poverty of stimulus argument}.
The two findings are that 18-month-olds can interpret phrases like ‘the red ball’ as having nested structure, although their experiences of language do not provide them with a basis for learning this.
The \gls{poverty of stimulus argument} goes like this:
%
\begin{enumerate}
  \item 18-month-olds can interpret phrases like ‘the red ball’ as having nested structure.
  \item To acquire this ability by data-driven learning would require experiences of utterances in which such phrases had to be understood as having nested structure.
  \item But extremely few such utterances are directed to 18-month-olds.
  \item So 18-month-olds do not acquire the ability to  interpret nested structure by data-driven learning.
  \item But all acquisition is either data-driven learning or innately-primed.
  \item So 18-month-olds’ acquisition of the ability to  interpret nested structure is innately-primed.%
  \footnote{%
  This is adapted from \citet[][]{pullum:2002_empirical}, who provide a detailed discussion of poverty of stimulus arguments.
  }
\end{enumerate}
%
Note that this argument establishes that something is innate but does not tell us what is innate.
The conclusion is not that the ability to interpret phrases like ‘the red ball’ as having nested structure is innate.
It is that acquiring this ability depends on something that is innate.
Establishing what that innate thing is would require further work.


Some linguists assume that some specifically syntactic abilities must be innate.
For instance, \citet[p.~25]{chomsky:1965_aspects} describes the linguists’ task as that of characterising the ‘innate linguistic theory that provides the basis for language learning.’
% ‘Thus what is maintained, presumably, is that the child has an innate theory of potential structural descriptions that is sufficiently rich and fully developed so that he is able to determine, from a real situation in which a signal occurs, which structural descriptions may be appropriate to this signal, and also that he is able to do this in part in advance of any assumption as to the linguistic structure of this signal.’
\Glspl{poverty of stimulus argument} provide no justification for this assumption.
For all those arguments reveal, it even may be that the innate capacities which enable the acquisition of syntactic abilities are domain-general.
Compare how things stand with the \gls{Principles of Object Perception} (see \cref{sec:principles-object-perception}).
When first encountered, there was a temptation to suppose that these principles are known or believed.
But on the leading view, there is no need to suppose this at all.
Instead the principles describe constraints on the operations of a system of object indexes (see \cref{sec:object-indexs-princ}).
Of course, the case of syntax differs from the case of physical objects in many ways.
I am not suggesting that we should take one case to provide a template for the other.
But reflection on the case of physical objects does suggest that in advance of an \gls{explanatorily adequate} theory,  nothing should be taken for granted about what in particular is innate.


How strong is \citeauthor{lidz:2003_what}’s argument for innateness?
The first premise, 1, is that 18-month-olds can interpret phrases like ‘the red ball’ as having nested structure.
To date this depends on evidence from a single lab, so should be regarded with caution.
The third premise is that few utterances in which phrases like ‘the red ball’ have to be interpreted as having nested structure are directed to infants.
Confidence in this premise should be high given that it is based on a large number of recorded utterances.
However, there is a possible line of objection linked to premise 2, which is about the need for such utterances.
\citeauthor{lidz:2003_what} considered utterances directed to infants where the nested interpretation of phrases like ‘the red ball’ is required to understand the sentence.
But it is possible in principle that infants may be exposed to some combination of linguistic and nonlinguistic evidence that enables them to arrive at the nested structure interpretation.
Attempts to develop a concrete objection along these lines (see \citealp{akhtar:2004_learning}) are not convincing \citep[pp.~161--2]{lidz:2004_reaffirming}.
While new discoveries about evidence or learning mechanisms are always possible, as things stand the balance of evidence appears to favour the view that some syntactic abilities depend on something innate.

This is a remarkable conclusion.
You might think that poverty of stimulus arguments have been around for a long time and are widely used to establish innateness, especially concerning syntax.
But it turns out that this is a myth.
As far as I know, \citeauthor{lidz:2003_what}’s is the only serious attempt to provide a poverty of stimulus argument for human syntactic abilities.



\section{The Poverty of Poverty of Stimulus Arguments}
\label{sec:poverty-of-poverty-of-stimulus}
Innateness is an exciting, attention grabbing topic.
Why risk destroying interest in it by focussing so narrowly on the case of ‘the red ball’?
% (If you have been reading from the start of the chapter, I am quite sure you never want to hear that phrase again.)
Consider an example of how poverty of stimulus arguments have been wielded in philosophy:
%
\begin{quote}
‘There would seem not to be enough ambient information available to account for the functional architecture that minds are found to have’ \citep[p.~35]{Fodor:1983dg}.
\end{quote}
%
It is hard to detect an argument here.
At least, if there is an argument, an equally compelling argument can be obtained by deleting the word ‘not’ from this sentence.

Things are not very different in linguistics.
In a recent defence of poverty of stimulus arguments for a conclusion about an innate basis for syntactic abilities, \citet{berwick:2011_poverty} cite no evidence at all concerning the experiences available in development.
They also cite no evidence at all concerning the development of syntactic abilities.
When making this sort of observation, I am usually told that the evidence is of a general nature and too familiar to need explicit mention.
But this is not quite right.
Instead \citeauthor{berwick:2011_poverty}’s argument has a familiar form, which I propose to label the \emph{\gls{poverty of theory argument}}:
%
\begin{enumerate}
  \item Current theories about how certain syntactic abilities are acquired are inadequate.
  \item So the acquisition of such abilities depends on innate representations of syntactic structure.
\end{enumerate}
%
It is important to distinguish poverty of theory arguments from poverty of stimulus arguments.
Poverty of theory arguments could be used to establish that almost everything is innate.
After all,  fully adequate developmental theories are scarce.
The problem, of course, is that poverty of theory arguments assume that the inadequacy of theories is not due to the inadequacy of theorists.
By contrast, poverty of stimulus arguments do not require this assumption.
Poverty of stimulus arguments therefore provide potentially more convincing grounds for accepting conclusions about innateness.
%Whatever their merits (you would need to be licensed to drive a bus in order to navigate the holes in poverty of theory arguments), it is important to distinguish poverty of theory arguments from poverty of stimulus arguments.
% Only the latter involve evidence concerning development and the availability of information.

Genuine poverty of stimulus arguments turn out to be rare.
In a thorough review,
\citeauthor{pullum:2002_empirical} observe that
%
\begin{quote} ‘the APS [poverty of stimulus argument] still awaits even a single good supporting example’
  (\citeyear[p.~47]{pullum:2002_empirical})
\end{quote}
%
Shortly after they wrote this, \citet{lidz:2003_what} published their example involving ‘the red ball’ (sorry!).
And that is the best, most careful attempt to provide a poverty of stimulus argument for human syntactic abilities to date.


\section{Social Aspects of Syntax}
\label{sec:social-aspects-of-syntax}
Could the developmental acquisition of syntactic abilities be entirely a consequence of experience and interaction?
Some researchers, notably \citeauthor{Tomasello:2003fk}, have proposed that they are.
On his view, children acquire facility with particular linguistic structures from their experiences of languages around them, and they acquire more general syntactic abilities on the basis of, and only after, acquiring particular structures (\citealp[p.~98]{Tomasello:2003fk}; see \citealp[part 4]{russell:2004_what} for a detailed critical evaluation of this view).

The existence of an innate basis for some syntactic abilities is a major challenge to this view.
But the finding that 18-month-olds have a relatively general ability to interpret phrases like ‘the red ball’ as having nested structure appears to be a decisive objection to Tomasello’s theory.%
\footnote{%
\citet{tomasello:2004_syntax} objects to \citet{lidz:2003_what}’s argument for innateness, and \citet{lidz:2004_reaffirming} object to Tomasello’s objection.
}

Should we therefore reject Tomasello’s approach outright?
Probably not.
One of Tomasello’s key arguments for his view is that, for children in typical linguistic environments, the emergence of syntactic abilities appears to depend on the expressions they are exposed to.
This general line of argument is also dramatically supported by research on the emergence of sign languages in Nicaragua.
(This research featured earlier, in \cref{sec:language-creation}.)
A group of \gls{homesign}ers were brought together.
Their environment provided no significant linguistic experience other than that they provided for each other.
In the process of communicating with each other by gesture they quickly developed ‘a peer-group pidgin or jargon’ called early Lenguaje de Señas Nicaragüense (LSN) \citep[p.~181]{Kegl:1999es}.
 At first, LSN was an ‘ever-changing’ mix of homesigns and new inventions lacking many grammatical features found in most other languages \citep[p.~212]{Kegl:1999es}.
 However, new cohorts including students under 10 years old and therefore young enough to acquire a native language soon entered the school.
 These students encountered LSN and, instead of reproducing it, did what children exposed to pidgins typically do—they systematised it, refined it, and added new features so that a new language, Idioma de Señas Nicaragüense (ISN), rapidly emerged.
The new language, ISN, involved syntactic features missing from the older LSN.
For example, the second cohort used spatial modulations as a grammatical device for indicating common reference.  Spatial modulations are fundamental building blocks used in all mature sign languages, but they are not used or understood by signers in the first cohort
\citep[p.~324]{Senghas:2001zm}.
The ability of one cohort to syntactically enrich the language of an earlier cohort indicates that syntactic development is probably not entirely a consequence of things that are innate but also depends on linguistic experience and communicative interactions.




\section{Is Core Knowledge Innate?}

\Gls{core knowledge} is often characterised by a list of properties including innateness \citep[for example,][p.~520]{Carey:1996hl}.
Why accept that all core knowledge is \gls{innate}?

\Glspl{poverty of stimulus argument} reveal that some abilities are innate in nonhumans \citep[for example,][]{chiandetti:2011_chicks_op}, and perhaps that something underpinning the acquisition of some syntactic abilities is innate (as we have just seen).
So there is no general reason to oppose claims about innateness.
On the other hand, in no domain other than syntax has a poverty of stimulus argument been provided.
(And even in the case of syntax, the critical evidence comes from a single lab.)
In the absence of  evidence for the innateness of core knowledge, and given how little is currently known about developing minds, it seems to me that we should be agnostic.
We do not currently know whether all core knowledge is innate.

Is there \gls{core knowledge} of syntax?
Answering this question is complicated by the fact that we currently lack an explanatorily robust theory of core knowledge (see \cref{sec:against-core-systems}).
Suppose we accept that there is core knowledge of objects, actions or minds.
Then there do not appear to be compelling reasons to distinguish between these domains and syntax.
As in the other domains, in the case of syntax there are early-developing abilities which are not knowledge and which appear to be important for the developmental emergence of knowledge.
If there is core knowledge of anything, there is probably also core knowledge of syntax.
For this reason I will adopt the working assumption that there is core knowledge of syntax in what follows.
If this assumption is correct, and if  \citeauthor{lidz:2003_what}’s poverty of stimulus argument succeeds (see \cref{sec:pos-argument}), then at least one form of core knowledge is innate.



\section{Syntax and Rediscovery}
How does knowledge of the syntactic aspects of utterances emerge in development?
Even in adults, syntactic abilities do not depend on knowledge of syntactic principles.
Instead they depend on something like core knowledge of syntax.
It is usually not until relatively late in life, and often as a consequence of formal education, that humans ever come to know facts about syntax, if they do at all.
As Fodor notes, in coming to know these facts we are rediscovering something that is in some sense already implicit in core knowledge of syntax:
%
\begin{quote}
‘when you learn about English syntax (e.g., in a linguistics course), what you are learning is something that, in some sense, you already knew’ \citep[p.~134, foonote~23]{Fodor:1983dg}.
\end{quote}
%
Further, the process of coming to know facts about syntax is clearly not a matter of transforming the contents of core knowledge states (if indeed they have contents) into the contents of knowledge states.
That is, the \gls{Assumption of Representational Connections} would not be correct in the case of syntax.
Core knowledge does not later become knowledge proper.
Instead, gaining knowledge of syntax is a paradigm case of development as \gls{rediscovery}.

What does rediscovery mean?
The things to be known are in some sense already implicit in your core knowledge, or in  early-developing capacities in you, such as the capacities which enable you to learn about the nested structure of phrases like ‘the red ball’.
Yet when you come to acquire the knowledge, you do so in roughly the way a linguist does.
The basis for learning is not the early-developing syntactic abilities but the things they enable you to do:
 to produce utterances which in fact have certain syntactic features, and to discriminate among utterances according to what are in fact their syntactic features.
Reflection on the behaviours and patterns of discrimination on your part, together with experience of these and social interaction with others typically involving instruction, eventually enables you to acquire knowledge about syntax (see \vref{fig:rediscovery_syntax.svg}).

\addFigure{rediscovery_syntax.svg}{The developmental emergence of knowledge of syntax involves \gls{rediscovery}.}

As in other cases, so for syntax: core knowledge or other early-developing abilities may play a key role in the emergence of knowledge not by providing building blocks for the contents of knowledge states but by enabling you to do, feel and experience things reflection on which together with social interaction plays a role in facilitating the emergence in development of knowledge.



\section{Conclusion}
How do humans first acquire knowledge of syntax in development?
Uniquely among the various domains of knowledge we have considered, physical objects, colours, actions and the rest, in the case of syntax there is evidence for innateness.
This evidence supports a \gls{poverty of stimulus argument}.
Utterances directed to children do not appear sufficient to specify some of the syntactic features which even 18-month-old infants take utterances to have.
This is a reason, not decisive but compelling, to hold that infants’ syntactic abilities depend on, or involve, something innate (see \cref{sec:pos-argument}).


% We do not currently know much about what is innate, however.
% Formally and descriptively adequate theories of syntactic abilities can be constructed using one or another set of principles.
% This motivates considering a counterpart of the \gls{Simple View} as a starting point: infants’ and adults’ syntactic abilities are based on knowledge of principles of syntax.
% But in the case of syntax, the Simple View manifestly generates systematically incorrect predictions (see \cref{sec:syntax-adults}).
% It must therefore be rejected.
% Developing an \gls{explanatorily adequate} theory for syntactic abilities remains a major challenge.

The discovery that something innate underpins some of infants’ syntactic abilities is a major breakthrough.
It shows that there is no general reason to hold that development in other domains could not depend on things that are innate.
And it supports the view that  early-developing abilities and states, perhaps including core knowledge, play an important role in development.
This is a major challenge to theories about the developmental emergence of knowledge which exclusively invoke social interaction (see \cref{sec:social-aspects-of-syntax}).

In opening this chapter, I mentioned that knowledge of language most clearly demonstrates the need for at least two ingredients in a theory of development, namely core knowledge and joint action.
Syntactic abilities are essential if referential communication is to become communication by language, of course.
But, conversely, there would be little point in having syntactic abilities without also being able to communicate.
Early in development, purposively communicative, referential actions are essentially forms of joint action, at least from an infant’s point of view (see \cref{cha:communication} and \cref{cha:words}).
What enables us to communicate by language is the combination of core knowledge of syntax and abilities for joint action.



%%% Local Variables:
%%% TeX-master: "master"
%%% End:
